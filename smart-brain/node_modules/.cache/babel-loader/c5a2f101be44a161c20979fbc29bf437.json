{"ast":null,"code":"var _jsxFileName = \"/Users/kylechart/Desktop/Websites/ztmwd-smartbrain/src/App.js\";\nimport React, { Component } from 'react'; // Standard inporting for react apps, if using normal js, no need for Component, but if using new react js, It is needed \n\nimport Clarifai from 'clarifai';\nimport Navigation from './Components/Navigation/Navigation';\nimport Logo from './Components/Logo/Logo';\nimport ImageLinkForm from './Components/ImageLinkForm/ImageLinkForm';\nimport Rank from './Components/Rank/Rank';\nimport FaceRecognition from './Components/FaceRecognition/FaceRecognition';\nimport SignIn from './Components/SignIn/SignIn';\nimport Registration from './Components/Registration/Registration';\nimport Particles from 'react-particles-js';\nimport './App.css';\nconst app = new Clarifai.App({\n  // This is telling the server that I am able to access the api with this key. Although not the same as every \n  apiKey: '46cd60645f2f41178e02fc35b1ad7ed7' // API It is very simaler to the rest, Each api has it own way of doing things, So just remember to read/follow\n\n}); // There instructions on the site, and you should have no problems\n\nconst particleOptions = {\n  // This is the particle effects on the background, It is fully customisable, link saved in dev space! Just adjust the \n  particles: {\n    // paramaters/numbers to change it! Everything explained on the website/git\n    number: {\n      value: 30,\n      density: {\n        enable: true,\n        value_area: 800\n      }\n    }\n  }\n};\n\nclass App extends Component {\n  // This is where all the main states for the app are to be defined\n  constructor() {\n    // When using the constructor, you have to use super() to be able to access it, otherwise it will return an error\n    super(); // Constructors allow you to set props that can be handed inside of functions and down to certain elements.\n\n    this.calculateFaceLocation = data => {\n      const clarifaiFace = data.outputs[0].data.regions[0].region_info.bounding_box; // This is getting the required data from the output that we receive from the image\n\n      const image = document.getElementById('inputImage'); // This is selecting the image for us and by using the information received above, we are able to manipulate the dom and add what we want\n\n      const width = Number(image.width);\n      const height = Number(image.height);\n      return {\n        // I dont understand the math, So just watch the video \n        leftCol: clarifaiFace.left_col * width,\n        topRow: clarifaiFace.top_row * height,\n        rightCol: width - clarifaiFace.right_col * width,\n        bottomRow: height - clarifaiFace.bottom_row * height\n      };\n    };\n\n    this.displayFaceBox = box => {\n      console.log(box);\n      this.setState({\n        box: box\n      });\n    };\n\n    this.onInputChange = event => {\n      this.setState({\n        input: event.target.value\n      }); // When a new input is detected inside of the text area, this is telling it to display what the input instructions\n    };\n\n    this.helloThere = () => {\n      // Button - I had problems getting the button name to work from the lesson, So i winged it! As from what I can tell, the example is now part of keywords.\n      this.setState({\n        imageUrl: this.state.input\n      });\n      app.models.predict(Clarifai.FACE_DETECT_MODEL, this.state.input) // In here, you can change what model is being detected by clarifai, by just changing the model according to what the api offers\n      .then(response => this.displayFaceBox(this.calculateFaceLocation(response))) // This will now call the above function, which will find the required data, and produce an output\t\n      .catch(err => console.log(err)); // Here it will catch any errors and log it into the console\n    };\n\n    this.onRouteChange = () => {\n      this.setState({\n        route: 'home'\n      }); // Must be wrapped inside curly brackets, as its an object\n    };\n\n    this.state = {\n      input: '',\n      imageUrl: '',\n      // The image url state is being used as the source, to be able to display the image\n      box: [],\n      // This constains the value's that we receive from the output, They are from the bounding_box we get below \n      route: 'signin' // This state keeps tracks of where we are in the app, and will adjust things accordingly! Such as not having the app open, until the user has signed into the app\n\n    };\n  }\n\n  render() {\n    return /*#__PURE__*/React.createElement(\"div\", {\n      className: \"App\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 80,\n        columnNumber: 3\n      }\n    }, /*#__PURE__*/React.createElement(Particles, {\n      className: \"Particles1\",\n      params: particleOptions,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 81,\n        columnNumber: 5\n      }\n    }), /*#__PURE__*/React.createElement(Navigation, {\n      onRouteChange: this.onRouteChange,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 82,\n        columnNumber: 5\n      }\n    }), this.state.route === 'signin' ? /*#__PURE__*/React.createElement(SignIn, {\n      onRouteChange: this.onRouteChange,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 84,\n        columnNumber: 7\n      }\n    }) // The function on here is changing the route of where it firects the user once signed in\n    :\n    /*#__PURE__*/\n    React.createElement(\"div\", {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 85,\n        columnNumber: 7\n      }\n    }, /*#__PURE__*/React.createElement(Logo, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 86,\n        columnNumber: 7\n      }\n    }), /*#__PURE__*/React.createElement(Rank, {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 87,\n        columnNumber: 7\n      }\n    }), /*#__PURE__*/React.createElement(ImageLinkForm, {\n      onInputChange: this.onInputChange,\n      helloThere: this.helloThere,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 88,\n        columnNumber: 7\n      }\n    }), /*#__PURE__*/React.createElement(FaceRecognition, {\n      box: this.state.box,\n      imageUrl: this.state.imageUrl,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 89,\n        columnNumber: 10\n      }\n    })));\n  }\n\n}\n\nexport default App; //  console.log(response.outputs[0].data.regions[0].region_info.bounding_box); // this is going into the output and selecting the specific information that we need\n// \tTo be able to add the face detection box.\n// For onInputChange to work, you have to use this. as it is a property of the app, otherwise it is undefined and will not register.\n// 90% of the styling in this app has been done with tachyons, this is an npm package, which is saved in my dev spave bookmarks which shows all the avalibale tags\n// Some has been self defined, and that means a css file has been made, and imported into the page\n// Calling setState() in React is asynchronous, for various reasons (mainly performance). Under the covers React will batch multiple calls to \n// setState() into a single call, and then re-render the component a single time, rather than re-rendering for every state change. Therefore the \n// imageUrl parameter would have never worked in our example, because when we called Clarifai with our the predict function, React wasn't finished \n// updating the state. \n// One way to go around this issue is to use a callback function:\n// setState(updater, callback)\n// Read more information here https://reactjs.org/docs/react-component.html#setstate\n// To make one js Component display before the others, set it a state of 'route' like above, and then use a conditional statmemnt. Remembering to wrap it in a div.\n// For deployment of react apps, you will need to use the npm build comand in the console! As this will compile all the nesecary files and dependencies \n// For the app to run, and it will do it in the most efficent way posisble!","map":{"version":3,"sources":["/Users/kylechart/Desktop/Websites/ztmwd-smartbrain/src/App.js"],"names":["React","Component","Clarifai","Navigation","Logo","ImageLinkForm","Rank","FaceRecognition","SignIn","Registration","Particles","app","App","apiKey","particleOptions","particles","number","value","density","enable","value_area","constructor","calculateFaceLocation","data","clarifaiFace","outputs","regions","region_info","bounding_box","image","document","getElementById","width","Number","height","leftCol","left_col","topRow","top_row","rightCol","right_col","bottomRow","bottom_row","displayFaceBox","box","console","log","setState","onInputChange","event","input","target","helloThere","imageUrl","state","models","predict","FACE_DETECT_MODEL","then","response","catch","err","onRouteChange","route","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC,C,CAA0C;;AAC1C,OAAOC,QAAP,MAAqB,UAArB;AACA,OAAOC,UAAP,MAAuB,oCAAvB;AACA,OAAOC,IAAP,MAAiB,wBAAjB;AACA,OAAOC,aAAP,MAA0B,0CAA1B;AACA,OAAOC,IAAP,MAAiB,wBAAjB;AACA,OAAOC,eAAP,MAA4B,8CAA5B;AACA,OAAOC,MAAP,MAAmB,4BAAnB;AACA,OAAOC,YAAP,MAAyB,wCAAzB;AACA,OAAOC,SAAP,MAAsB,oBAAtB;AAEA,OAAO,WAAP;AAEA,MAAMC,GAAG,GAAG,IAAIT,QAAQ,CAACU,GAAb,CAAiB;AAAO;AACnCC,EAAAA,MAAM,EAAE,kCADoB,CACgB;;AADhB,CAAjB,CAAZ,C,CAEc;;AAEd,MAAMC,eAAe,GAAG;AAAE;AACzBC,EAAAA,SAAS,EAAE;AAAK;AACfC,IAAAA,MAAM,EAAE;AACPC,MAAAA,KAAK,EAAE,EADA;AAERC,MAAAA,OAAO,EAAE;AACRC,QAAAA,MAAM,EAAE,IADA;AAERC,QAAAA,UAAU,EAAE;AAFJ;AAFD;AADE;AADY,CAAxB;;AAYA,MAAMR,GAAN,SAAkBX,SAAlB,CAA4B;AAAE;AAC7BoB,EAAAA,WAAW,GAAG;AAAE;AACf,YADa,CACJ;;AADI,SAUfC,qBAVe,GAUUC,IAAD,IAAU;AACjC,YAAMC,YAAY,GAAID,IAAI,CAACE,OAAL,CAAa,CAAb,EAAgBF,IAAhB,CAAqBG,OAArB,CAA6B,CAA7B,EAAgCC,WAAhC,CAA4CC,YAAlE,CADiC,CAC+C;;AAC/E,YAAMC,KAAK,GAAGC,QAAQ,CAACC,cAAT,CAAwB,YAAxB,CAAd,CAFgC,CAEsB;;AACtD,YAAMC,KAAK,GAAGC,MAAM,CAACJ,KAAK,CAACG,KAAP,CAApB;AACA,YAAME,MAAM,GAAGD,MAAM,CAACJ,KAAK,CAACK,MAAP,CAArB;AACA,aAAO;AAAY;AAClBC,QAAAA,OAAO,EAAEX,YAAY,CAACY,QAAb,GAAwBJ,KAD3B;AAENK,QAAAA,MAAM,EAAEb,YAAY,CAACc,OAAb,GAAuBJ,MAFzB;AAGNK,QAAAA,QAAQ,EAAEP,KAAK,GAAIR,YAAY,CAACgB,SAAb,GAAyBR,KAHtC;AAINS,QAAAA,SAAS,EAAEP,MAAM,GAAIV,YAAY,CAACkB,UAAb,GAA0BR;AAJzC,OAAP;AAMD,KArBc;;AAAA,SAuBfS,cAvBe,GAuBGC,GAAD,IAAS;AACzBC,MAAAA,OAAO,CAACC,GAAR,CAAYF,GAAZ;AACA,WAAKG,QAAL,CAAc;AAACH,QAAAA,GAAG,EAAEA;AAAN,OAAd;AACA,KA1Bc;;AAAA,SA4BfI,aA5Be,GA4BEC,KAAD,IAAW;AAC1B,WAAKF,QAAL,CAAc;AAACG,QAAAA,KAAK,EAAED,KAAK,CAACE,MAAN,CAAalC;AAArB,OAAd,EAD0B,CACkB;AAC5C,KA9Bc;;AAAA,SAkCfmC,UAlCe,GAkCF,MAAM;AAAE;AACpB,WAAKL,QAAL,CAAc;AAACM,QAAAA,QAAQ,EAAE,KAAKC,KAAL,CAAWJ;AAAtB,OAAd;AACCvC,MAAAA,GAAG,CAAC4C,MAAJ,CAAWC,OAAX,CAAmBtD,QAAQ,CAACuD,iBAA5B,EAA+C,KAAKH,KAAL,CAAWJ,KAA1D,EAAiE;AAAjE,OACCQ,IADD,CACMC,QAAQ,IAAI,KAAKhB,cAAL,CAAoB,KAAKrB,qBAAL,CAA2BqC,QAA3B,CAApB,CADlB,EAC6E;AAD7E,OAEEC,KAFF,CAEQC,GAAG,IAAIhB,OAAO,CAACC,GAAR,CAAYe,GAAZ,CAFf,EAFiB,CAIyB;AAC3C,KAvCc;;AAAA,SA2CfC,aA3Ce,GA2CC,MAAM;AACrB,WAAKf,QAAL,CAAc;AAACgB,QAAAA,KAAK,EAAE;AAAR,OAAd,EADqB,CACW;AAChC,KA7Cc;;AAEb,SAAKT,KAAL,GAAa;AACZJ,MAAAA,KAAK,EAAE,EADK;AAEZG,MAAAA,QAAQ,EAAE,EAFE;AAEE;AACdT,MAAAA,GAAG,EAAE,EAHO;AAGH;AACTmB,MAAAA,KAAK,EAAE,QAJK,CAIK;;AAJL,KAAb;AAMA;;AAuCFC,EAAAA,MAAM,GAAG;AACR,wBACC;AAAK,MAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACE,oBAAC,SAAD;AAAW,MAAA,SAAS,EAAC,YAArB;AAAkC,MAAA,MAAM,EAAElD,eAA1C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,eAEE,oBAAC,UAAD;AAAY,MAAA,aAAa,EAAE,KAAKgD,aAAhC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAFF,EAGI,KAAKR,KAAL,CAAWS,KAAX,KAAqB,QAArB,gBACA,oBAAC,MAAD;AAAQ,MAAA,aAAa,EAAE,KAAKD,aAA5B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADA,CAC6C;AAD7C;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACA,oBAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADA,eAEA,oBAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAFA,eAGA,oBAAC,aAAD;AAAe,MAAA,aAAa,EAAE,KAAKd,aAAnC;AAAkD,MAAA,UAAU,EAAE,KAAKI,UAAnE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAHA,eAIG,oBAAC,eAAD;AAAiB,MAAA,GAAG,EAAE,KAAKE,KAAL,CAAWV,GAAjC;AAAsC,MAAA,QAAQ,EAAE,KAAKU,KAAL,CAAWD,QAA3D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAJH,CALJ,CADD;AAeA;;AAhE2B;;AAmE5B,eAAezC,GAAf,C,CAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAEA;AACA","sourcesContent":["import React, { Component } from 'react'; // Standard inporting for react apps, if using normal js, no need for Component, but if using new react js, It is needed \nimport Clarifai from 'clarifai';\nimport Navigation from './Components/Navigation/Navigation';\nimport Logo from './Components/Logo/Logo';\nimport ImageLinkForm from './Components/ImageLinkForm/ImageLinkForm';\nimport Rank from './Components/Rank/Rank'\nimport FaceRecognition from './Components/FaceRecognition/FaceRecognition';\nimport SignIn from './Components/SignIn/SignIn';\nimport Registration from './Components/Registration/Registration';\nimport Particles from 'react-particles-js';\n\nimport './App.css';\n\nconst app = new Clarifai.App({ \t\t\t\t\t// This is telling the server that I am able to access the api with this key. Although not the same as every \n\tapiKey: '46cd60645f2f41178e02fc35b1ad7ed7'  // API It is very simaler to the rest, Each api has it own way of doing things, So just remember to read/follow\n})\t\t\t\t\t\t\t\t\t\t\t\t// There instructions on the site, and you should have no problems\n\nconst particleOptions = { // This is the particle effects on the background, It is fully customisable, link saved in dev space! Just adjust the \n\tparticles: {\t\t  // paramaters/numbers to change it! Everything explained on the website/git\n\t\tnumber: {\n\t\t\tvalue: 30,\n\t\tdensity: {\n\t\t\tenable: true,\n\t\t\tvalue_area: 800,\n\t\t}\n\t}\n}\n}\n\nclass App extends Component { // This is where all the main states for the app are to be defined\n\tconstructor() { // When using the constructor, you have to use super() to be able to access it, otherwise it will return an error\n\t\tsuper();\t// Constructors allow you to set props that can be handed inside of functions and down to certain elements.\n\t\tthis.state = {\n\t\t\tinput: '',\n\t\t\timageUrl: '', // The image url state is being used as the source, to be able to display the image\n\t\t\tbox: [],\t// This constains the value's that we receive from the output, They are from the bounding_box we get below \n\t\t\troute: 'signin'  // This state keeps tracks of where we are in the app, and will adjust things accordingly! Such as not having the app open, until the user has signed into the app\n\t\t}\n\t} \n\ncalculateFaceLocation = (data) => {\n\tconst clarifaiFace  = data.outputs[0].data.regions[0].region_info.bounding_box; // This is getting the required data from the output that we receive from the image\n\t\tconst image = document.getElementById('inputImage'); \t// This is selecting the image for us and by using the information received above, we are able to manipulate the dom and add what we want\n\t\tconst width = Number(image.width);\n\t\tconst height = Number(image.height);\n\t\treturn {\t\t\t\t\t\t\t\t\t\t\t// I dont understand the math, So just watch the video \n\t\t\tleftCol: clarifaiFace.left_col * width,\n\t\t\ttopRow: clarifaiFace.top_row * height,\n\t\t\trightCol: width - (clarifaiFace.right_col * width),\n\t\t\tbottomRow: height - (clarifaiFace.bottom_row * height)\n\t\t}\n}\n\ndisplayFaceBox = (box) => {\n\tconsole.log(box)\n\tthis.setState({box: box})\n}\n\nonInputChange = (event) => {\n\tthis.setState({input: event.target.value}); // When a new input is detected inside of the text area, this is telling it to display what the input instructions\n}\t\t\t\t\t\t\t\t\t\t\t\t// in this case, its displaying an image. If we were just logging the event, we could detect anything inside\n\t\t\t\t\t\t\t\t\t\t\t\t// Of the input box, such as text! \n// To get the value of the input, you need to use the above code in the console.log paramaters\n\nhelloThere = () => { // Button - I had problems getting the button name to work from the lesson, So i winged it! As from what I can tell, the example is now part of keywords.\n\tthis.setState({imageUrl: this.state.input});\n\t\tapp.models.predict(Clarifai.FACE_DETECT_MODEL, this.state.input) // In here, you can change what model is being detected by clarifai, by just changing the model according to what the api offers\n\t\t.then(response => this.displayFaceBox(this.calculateFaceLocation(response))) // This will now call the above function, which will find the required data, and produce an output\t\n\t \t.catch(err => console.log(err))\t\t\t\t\t\t \t\t // Here it will catch any errors and log it into the console\n}\n\n// By using the arror functions, we are able to clean this up and make the code flow better making it easier to read. This is due to the constant updates of the language.\n\nonRouteChange = () => {\n\tthis.setState({route: 'home'}); // Must be wrapped inside curly brackets, as its an object\n}\n\nrender() {\n\treturn (\n\t\t<div className=\"App\">\n\t\t\t <Particles className='Particles1' params={particleOptions}/> \n\t\t\t <Navigation onRouteChange={this.onRouteChange} />\n\t\t\t { this.state.route === 'signin' \n\t\t\t ? <SignIn onRouteChange={this.onRouteChange}/> // The function on here is changing the route of where it firects the user once signed in\n\t\t\t : <div>\n\t\t\t \t\t<Logo />\n\t\t\t \t\t<Rank />\n\t\t\t \t\t<ImageLinkForm onInputChange={this.onInputChange} helloThere={this.helloThere}/> \n\t\t     \t\t<FaceRecognition box={this.state.box} imageUrl={this.state.imageUrl}/>\n\t\t       </div>\n\t\t    }\n\t\t</div>\n\t);\n}\n}\n\nexport default App;\n \n//  console.log(response.outputs[0].data.regions[0].region_info.bounding_box); // this is going into the output and selecting the specific information that we need\n// \tTo be able to add the face detection box.\n\n// For onInputChange to work, you have to use this. as it is a property of the app, otherwise it is undefined and will not register.\n// 90% of the styling in this app has been done with tachyons, this is an npm package, which is saved in my dev spave bookmarks which shows all the avalibale tags\n// Some has been self defined, and that means a css file has been made, and imported into the page\n\n// Calling setState() in React is asynchronous, for various reasons (mainly performance). Under the covers React will batch multiple calls to \n// setState() into a single call, and then re-render the component a single time, rather than re-rendering for every state change. Therefore the \n// imageUrl parameter would have never worked in our example, because when we called Clarifai with our the predict function, React wasn't finished \n// updating the state. \n\n// One way to go around this issue is to use a callback function:\n// setState(updater, callback)\n\n// Read more information here https://reactjs.org/docs/react-component.html#setstate\n\n// To make one js Component display before the others, set it a state of 'route' like above, and then use a conditional statmemnt. Remembering to wrap it in a div.\n\n// For deployment of react apps, you will need to use the npm build comand in the console! As this will compile all the nesecary files and dependencies \n// For the app to run, and it will do it in the most efficent way posisble!\n\n\n"]},"metadata":{},"sourceType":"module"}